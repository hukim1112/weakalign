{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeakAlign demo notebook\n",
    "\n",
    "This notebook shows how to run a trained model on a given image pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "from os.path import exists\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model.cnn_geometric_model import CNNGeometric, TwoStageCNNGeometric\n",
    "from data.pf_dataset import PFDataset\n",
    "from data.download_datasets import download_PF_pascal\n",
    "from image.normalization import NormalizeImageDict, normalize_image\n",
    "from util.torch_util import BatchTensorToVars, str_to_bool\n",
    "from geotnf.transformation import GeometricTnf\n",
    "from geotnf.point_tnf import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import warnings\n",
    "from torchvision.transforms import Normalize\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.loss import TransformedGridLoss, WeakInlierCount, TwoStageWeakInlierCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one of the following models:\n",
    "# cnngeo_vgg16, cnngeo_resnet101, proposed_resnet101\n",
    "model_selection = 'proposed_resnet101' \n",
    "\n",
    "model_aff_path = ''\n",
    "model_tps_path = ''\n",
    "model_aff_tps_path = ''\n",
    "\n",
    "if model_selection=='cnngeo_vgg16':\n",
    "    model_aff_path = 'trained_models/trained_models/cnngeo_vgg16_affine.pth.tar'\n",
    "    model_tps_path = 'trained_models/trained_models/cnngeo_vgg16_tps.pth.tar'\n",
    "    feature_extraction_cnn = 'vgg'\n",
    "    \n",
    "elif model_selection=='cnngeo_resnet101':\n",
    "    model_aff_path = 'trained_models/trained_models/cnngeo_resnet101_affine.pth.tar'\n",
    "    model_tps_path = 'trained_models/trained_models/cnngeo_resnet101_tps.pth.tar'   \n",
    "    feature_extraction_cnn = 'resnet101'\n",
    "    \n",
    "elif model_selection=='proposed_resnet101':\n",
    "    model_aff_tps_path = 'trained_models/weakalign_resnet101_affine_tps.pth.tar'\n",
    "    feature_extraction_cnn = 'resnet101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "model = TwoStageCNNGeometric(use_cuda=use_cuda,\n",
    "                             return_correlation=True,\n",
    "                             feature_extraction_cnn=feature_extraction_cnn)\n",
    "\n",
    "# load pre-trained model\n",
    "if model_aff_tps_path!='':\n",
    "    checkpoint = torch.load(model_aff_tps_path, map_location=lambda storage, loc: storage)\n",
    "    checkpoint['state_dict'] = OrderedDict([(k.replace('vgg', 'model'), v) for k, v in checkpoint['state_dict'].items()])\n",
    "        \n",
    "    for name, param in model.FeatureExtraction.state_dict().items():\n",
    "        model.FeatureExtraction.state_dict()[name].copy_(checkpoint['state_dict']['FeatureExtraction.' + name])    \n",
    "    for name, param in model.FeatureRegression.state_dict().items():\n",
    "        model.FeatureRegression.state_dict()[name].copy_(checkpoint['state_dict']['FeatureRegression.' + name])\n",
    "    for name, param in model.FeatureRegression2.state_dict().items():\n",
    "        model.FeatureRegression2.state_dict()[name].copy_(checkpoint['state_dict']['FeatureRegression2.' + name])    \n",
    "else:\n",
    "    checkpoint_aff = torch.load(model_aff_path, map_location=lambda storage, loc: storage)\n",
    "    checkpoint_aff['state_dict'] = OrderedDict([(k.replace('vgg', 'model'), v) for k, v in checkpoint_aff['state_dict'].items()])\n",
    "    for name, param in model.FeatureExtraction.state_dict().items():\n",
    "        model.FeatureExtraction.state_dict()[name].copy_(checkpoint_aff['state_dict']['FeatureExtraction.' + name])    \n",
    "    for name, param in model.FeatureRegression.state_dict().items():\n",
    "        model.FeatureRegression.state_dict()[name].copy_(checkpoint_aff['state_dict']['FeatureRegression.' + name])\n",
    "\n",
    "    checkpoint_tps = torch.load(model_tps_path, map_location=lambda storage, loc: storage)\n",
    "    checkpoint_tps['state_dict'] = OrderedDict([(k.replace('vgg', 'model'), v) for k, v in checkpoint_tps['state_dict'].items()])\n",
    "    for name, param in model.FeatureRegression2.state_dict().items():\n",
    "        model.FeatureRegression2.state_dict()[name].copy_(checkpoint_tps['state_dict']['FeatureRegression.' + name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create image transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpsTnf = GeometricTnf(geometric_model='tps', use_cuda=use_cuda)\n",
    "affTnf = GeometricTnf(geometric_model='affine', use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-imagenet dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 350, 84, 84, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load Train Dataset\n",
    "data_generator_path = os.environ['DATA_GENERATOR']\n",
    "test_split_path = os.path.join(data_generator_path, \"datasets/mini-imagenet/npy\", \"mini-imagenet-test.npy\")\n",
    "test_dataset = np.load(test_split_path)\n",
    "n_classes = test_dataset.shape[0]\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episodic test Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_episodes = 100\n",
    "n_way = 20\n",
    "n_shot = 5\n",
    "n_query = 15\n",
    "n_examples = 350\n",
    "im_width, im_height, channels = 84, 84, 3\n",
    "h_dim = 64\n",
    "z_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_episodes = 600\n",
    "n_test_way = 5\n",
    "n_test_shot = 5\n",
    "n_test_query = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_groups = {'tps_grid_size': 3, \n",
    "              'tps_reg_factor': 0.2, \n",
    "              'normalize_inlier_count': True, \n",
    "              'dilation_filter': 0, 'use_conv_filter': False}\n",
    "inliersAffine = WeakInlierCount(geometric_model='affine',**arg_groups)\n",
    "#inliersTps = WeakInlierCount(geometric_model='tps',**arg_groups['weak_loss'])\n",
    "inliersComposed = TwoStageWeakInlierCount(use_cuda=use_cuda,**arg_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeCNN = GeometricTnf(out_h=240, out_w=240, use_cuda = False) \n",
    "normalizeTnf = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # convert to torch Variable\n",
    "    image = np.expand_dims(image.transpose((2,0,1)),0)\n",
    "    image = torch.Tensor(image.astype(np.float32)/255.0)\n",
    "    image_var = Variable(image,requires_grad=False)\n",
    "\n",
    "    # Resize image using bilinear sampling with identity affine tnf\n",
    "    image_var = resizeCNN(image_var)\n",
    "    \n",
    "    # Normalize image\n",
    "    image_var = normalize_image(image_var)\n",
    "    \n",
    "    return image_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_scoring(src, trg):\n",
    "    source_image_var = preprocess_image(src)\n",
    "    target_image_var = preprocess_image(trg)\n",
    "\n",
    "    if use_cuda:\n",
    "        source_image_var = source_image_var.cuda()\n",
    "        target_image_var = target_image_var.cuda()\n",
    "\n",
    "    batch = {'source_image': source_image_var, 'target_image':target_image_var}   \n",
    "    theta_aff,theta_aff_tps,corr_aff,corr_aff_tps=model(batch)\n",
    "    inliers_comp = inliersComposed(matches=corr_aff,theta_aff=theta_aff,theta_aff_tps=theta_aff_tps)\n",
    "    inliers_aff = inliersAffine(matches=corr_aff,theta=theta_aff)\n",
    "    return (inliers_aff+inliers_comp).data.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoStageCNNGeometric(\n",
       "  (FeatureExtraction): FeatureExtraction(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (FeatureCorrelation): FeatureCorrelation(\n",
       "    (ReLU): ReLU()\n",
       "  )\n",
       "  (FeatureRegression): FeatureRegression(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(225, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (5): ReLU(inplace)\n",
       "    )\n",
       "    (linear): Linear(in_features=1600, out_features=6, bias=True)\n",
       "  )\n",
       "  (ReLU): ReLU(inplace)\n",
       "  (FeatureRegression2): FeatureRegression(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(225, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (5): ReLU(inplace)\n",
       "    )\n",
       "    (linear): Linear(in_features=1600, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "[test episode 1/600] => acc: 0.84000\n",
      "[test episode 2/600] => acc: 0.62667\n",
      "[test episode 3/600] => acc: 0.46667\n",
      "[test episode 4/600] => acc: 0.86667\n",
      "[test episode 5/600] => acc: 0.86667\n",
      "[test episode 6/600] => acc: 0.74667\n",
      "[test episode 7/600] => acc: 0.65333\n",
      "[test episode 8/600] => acc: 0.72000\n",
      "[test episode 9/600] => acc: 0.76000\n",
      "[test episode 10/600] => acc: 0.62667\n",
      "[test episode 11/600] => acc: 0.69333\n",
      "[test episode 12/600] => acc: 0.77333\n",
      "[test episode 13/600] => acc: 0.66667\n",
      "[test episode 14/600] => acc: 0.65333\n",
      "[test episode 15/600] => acc: 0.73333\n",
      "[test episode 16/600] => acc: 0.62667\n",
      "[test episode 17/600] => acc: 0.88000\n",
      "[test episode 18/600] => acc: 0.73333\n",
      "[test episode 19/600] => acc: 0.68000\n",
      "[test episode 20/600] => acc: 0.61333\n",
      "[test episode 21/600] => acc: 0.66667\n",
      "[test episode 22/600] => acc: 0.65333\n",
      "[test episode 23/600] => acc: 0.64000\n",
      "[test episode 24/600] => acc: 0.81333\n",
      "[test episode 25/600] => acc: 0.76000\n",
      "[test episode 26/600] => acc: 0.68000\n",
      "[test episode 27/600] => acc: 0.52000\n",
      "[test episode 28/600] => acc: 0.77333\n",
      "[test episode 29/600] => acc: 0.58667\n",
      "[test episode 30/600] => acc: 0.68000\n",
      "[test episode 31/600] => acc: 0.66667\n",
      "[test episode 32/600] => acc: 0.81333\n",
      "[test episode 33/600] => acc: 0.73333\n",
      "[test episode 34/600] => acc: 0.70667\n",
      "[test episode 35/600] => acc: 0.76000\n",
      "[test episode 36/600] => acc: 0.72000\n",
      "[test episode 37/600] => acc: 0.54667\n",
      "[test episode 38/600] => acc: 0.66667\n",
      "[test episode 39/600] => acc: 0.61333\n",
      "[test episode 40/600] => acc: 0.74667\n",
      "[test episode 41/600] => acc: 0.65333\n",
      "[test episode 42/600] => acc: 0.70667\n",
      "[test episode 43/600] => acc: 0.86667\n",
      "[test episode 44/600] => acc: 0.76000\n",
      "[test episode 45/600] => acc: 0.81333\n",
      "[test episode 46/600] => acc: 0.70667\n",
      "[test episode 47/600] => acc: 0.77333\n",
      "[test episode 48/600] => acc: 0.68000\n",
      "[test episode 49/600] => acc: 0.73333\n",
      "[test episode 50/600] => acc: 0.73333\n",
      "[test episode 51/600] => acc: 0.62667\n",
      "[test episode 52/600] => acc: 0.65333\n",
      "[test episode 53/600] => acc: 0.70667\n",
      "[test episode 54/600] => acc: 0.66667\n",
      "[test episode 55/600] => acc: 0.58667\n",
      "[test episode 56/600] => acc: 0.84000\n",
      "[test episode 57/600] => acc: 0.84000\n",
      "[test episode 58/600] => acc: 0.70667\n",
      "[test episode 59/600] => acc: 0.76000\n",
      "[test episode 60/600] => acc: 0.73333\n",
      "[test episode 61/600] => acc: 0.73333\n",
      "[test episode 62/600] => acc: 0.78667\n",
      "[test episode 63/600] => acc: 0.84000\n",
      "[test episode 64/600] => acc: 0.80000\n",
      "[test episode 65/600] => acc: 0.57333\n",
      "[test episode 66/600] => acc: 0.60000\n",
      "[test episode 67/600] => acc: 0.66667\n",
      "[test episode 68/600] => acc: 0.73333\n",
      "[test episode 69/600] => acc: 0.80000\n",
      "[test episode 70/600] => acc: 0.64000\n",
      "[test episode 71/600] => acc: 0.74667\n",
      "[test episode 72/600] => acc: 0.92000\n",
      "[test episode 73/600] => acc: 0.81333\n",
      "[test episode 74/600] => acc: 0.81333\n",
      "[test episode 75/600] => acc: 0.74667\n",
      "[test episode 76/600] => acc: 0.74667\n",
      "[test episode 77/600] => acc: 0.60000\n",
      "[test episode 78/600] => acc: 0.61333\n",
      "[test episode 79/600] => acc: 0.52000\n",
      "[test episode 80/600] => acc: 0.62667\n",
      "[test episode 81/600] => acc: 0.50667\n",
      "[test episode 82/600] => acc: 0.78667\n",
      "[test episode 83/600] => acc: 0.69333\n",
      "[test episode 84/600] => acc: 0.72000\n",
      "[test episode 85/600] => acc: 0.86667\n",
      "[test episode 86/600] => acc: 0.85333\n",
      "[test episode 87/600] => acc: 0.54667\n",
      "[test episode 88/600] => acc: 0.81333\n",
      "[test episode 89/600] => acc: 0.74667\n",
      "[test episode 90/600] => acc: 0.76000\n",
      "[test episode 91/600] => acc: 0.64000\n",
      "[test episode 92/600] => acc: 0.92000\n",
      "[test episode 93/600] => acc: 0.76000\n",
      "[test episode 94/600] => acc: 0.65333\n",
      "[test episode 95/600] => acc: 0.62667\n",
      "[test episode 96/600] => acc: 0.81333\n",
      "[test episode 97/600] => acc: 0.61333\n",
      "[test episode 98/600] => acc: 0.77333\n",
      "[test episode 99/600] => acc: 0.85333\n",
      "[test episode 100/600] => acc: 0.69333\n",
      "[test episode 101/600] => acc: 0.82667\n",
      "[test episode 102/600] => acc: 0.81333\n",
      "[test episode 103/600] => acc: 0.76000\n",
      "[test episode 104/600] => acc: 0.84000\n",
      "[test episode 105/600] => acc: 0.73333\n",
      "[test episode 106/600] => acc: 0.82667\n",
      "[test episode 107/600] => acc: 0.82667\n",
      "[test episode 108/600] => acc: 0.58667\n",
      "[test episode 109/600] => acc: 0.70667\n",
      "[test episode 110/600] => acc: 0.77333\n",
      "[test episode 111/600] => acc: 0.70667\n",
      "[test episode 112/600] => acc: 0.73333\n",
      "[test episode 113/600] => acc: 0.65333\n",
      "[test episode 114/600] => acc: 0.81333\n",
      "[test episode 115/600] => acc: 0.74667\n",
      "[test episode 116/600] => acc: 0.72000\n",
      "[test episode 117/600] => acc: 0.82667\n",
      "[test episode 118/600] => acc: 0.69333\n",
      "[test episode 119/600] => acc: 0.81333\n",
      "[test episode 120/600] => acc: 0.70667\n",
      "[test episode 121/600] => acc: 0.66667\n",
      "[test episode 122/600] => acc: 0.65333\n",
      "[test episode 123/600] => acc: 0.69333\n",
      "[test episode 124/600] => acc: 0.78667\n",
      "[test episode 125/600] => acc: 0.81333\n",
      "[test episode 126/600] => acc: 0.93333\n",
      "[test episode 127/600] => acc: 0.62667\n",
      "[test episode 128/600] => acc: 0.73333\n",
      "[test episode 129/600] => acc: 0.85333\n",
      "[test episode 130/600] => acc: 0.77333\n",
      "[test episode 131/600] => acc: 0.58667\n",
      "[test episode 132/600] => acc: 0.80000\n",
      "[test episode 133/600] => acc: 0.85333\n",
      "[test episode 134/600] => acc: 0.73333\n",
      "[test episode 135/600] => acc: 0.82667\n",
      "[test episode 136/600] => acc: 0.69333\n",
      "[test episode 137/600] => acc: 0.74667\n",
      "[test episode 138/600] => acc: 0.82667\n",
      "[test episode 139/600] => acc: 0.76000\n",
      "[test episode 140/600] => acc: 0.88000\n",
      "[test episode 141/600] => acc: 0.70667\n",
      "[test episode 142/600] => acc: 0.78667\n",
      "[test episode 143/600] => acc: 0.65333\n",
      "[test episode 144/600] => acc: 0.66667\n",
      "[test episode 145/600] => acc: 0.68000\n",
      "[test episode 146/600] => acc: 0.85333\n",
      "[test episode 147/600] => acc: 0.64000\n",
      "[test episode 148/600] => acc: 0.78667\n",
      "[test episode 149/600] => acc: 0.86667\n",
      "[test episode 150/600] => acc: 0.76000\n",
      "[test episode 151/600] => acc: 0.72000\n",
      "[test episode 152/600] => acc: 0.81333\n",
      "[test episode 153/600] => acc: 0.88000\n",
      "[test episode 154/600] => acc: 0.80000\n",
      "[test episode 155/600] => acc: 0.90667\n",
      "[test episode 156/600] => acc: 0.65333\n",
      "[test episode 157/600] => acc: 0.74667\n",
      "[test episode 158/600] => acc: 0.77333\n",
      "[test episode 159/600] => acc: 0.60000\n",
      "[test episode 160/600] => acc: 0.68000\n",
      "[test episode 161/600] => acc: 0.81333\n",
      "[test episode 162/600] => acc: 0.57333\n",
      "[test episode 163/600] => acc: 0.66667\n",
      "[test episode 164/600] => acc: 0.73333\n",
      "[test episode 165/600] => acc: 0.65333\n",
      "[test episode 166/600] => acc: 0.80000\n",
      "[test episode 167/600] => acc: 0.69333\n",
      "[test episode 168/600] => acc: 0.72000\n",
      "[test episode 169/600] => acc: 0.69333\n",
      "[test episode 170/600] => acc: 0.62667\n",
      "[test episode 171/600] => acc: 0.60000\n",
      "[test episode 172/600] => acc: 0.80000\n",
      "[test episode 173/600] => acc: 0.81333\n",
      "[test episode 174/600] => acc: 0.73333\n",
      "[test episode 175/600] => acc: 0.84000\n",
      "[test episode 176/600] => acc: 0.84000\n",
      "[test episode 177/600] => acc: 0.84000\n",
      "[test episode 178/600] => acc: 0.84000\n",
      "[test episode 179/600] => acc: 0.50667\n",
      "[test episode 180/600] => acc: 0.73333\n",
      "[test episode 181/600] => acc: 0.58667\n",
      "[test episode 182/600] => acc: 0.81333\n",
      "[test episode 183/600] => acc: 0.58667\n",
      "[test episode 184/600] => acc: 0.72000\n",
      "[test episode 185/600] => acc: 0.57333\n",
      "[test episode 186/600] => acc: 0.70667\n",
      "[test episode 187/600] => acc: 0.69333\n",
      "[test episode 188/600] => acc: 0.76000\n",
      "[test episode 189/600] => acc: 0.77333\n",
      "[test episode 190/600] => acc: 0.65333\n",
      "[test episode 191/600] => acc: 0.69333\n",
      "[test episode 192/600] => acc: 0.73333\n",
      "[test episode 193/600] => acc: 0.68000\n",
      "[test episode 194/600] => acc: 0.61333\n",
      "[test episode 195/600] => acc: 0.77333\n",
      "[test episode 196/600] => acc: 0.68000\n",
      "[test episode 197/600] => acc: 0.73333\n",
      "[test episode 198/600] => acc: 0.69333\n",
      "[test episode 199/600] => acc: 0.77333\n",
      "[test episode 200/600] => acc: 0.82667\n",
      "[test episode 201/600] => acc: 0.74667\n",
      "[test episode 202/600] => acc: 0.68000\n",
      "[test episode 203/600] => acc: 0.60000\n",
      "[test episode 204/600] => acc: 0.73333\n",
      "[test episode 205/600] => acc: 0.80000\n",
      "[test episode 206/600] => acc: 0.85333\n",
      "[test episode 207/600] => acc: 0.58667\n",
      "[test episode 208/600] => acc: 0.74667\n",
      "[test episode 209/600] => acc: 0.86667\n",
      "[test episode 210/600] => acc: 0.77333\n",
      "[test episode 211/600] => acc: 0.74667\n",
      "[test episode 212/600] => acc: 0.82667\n",
      "[test episode 213/600] => acc: 0.74667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test episode 214/600] => acc: 0.74667\n",
      "[test episode 215/600] => acc: 0.82667\n",
      "[test episode 216/600] => acc: 0.62667\n",
      "[test episode 217/600] => acc: 0.86667\n",
      "[test episode 218/600] => acc: 0.85333\n",
      "[test episode 219/600] => acc: 0.48000\n",
      "[test episode 220/600] => acc: 0.68000\n",
      "[test episode 221/600] => acc: 0.69333\n",
      "[test episode 222/600] => acc: 0.80000\n",
      "[test episode 223/600] => acc: 0.72000\n",
      "[test episode 224/600] => acc: 0.62667\n",
      "[test episode 225/600] => acc: 0.69333\n",
      "[test episode 226/600] => acc: 0.57333\n",
      "[test episode 227/600] => acc: 0.70667\n",
      "[test episode 228/600] => acc: 0.64000\n",
      "[test episode 229/600] => acc: 0.90667\n",
      "[test episode 230/600] => acc: 0.73333\n",
      "[test episode 231/600] => acc: 0.80000\n",
      "[test episode 232/600] => acc: 0.72000\n",
      "[test episode 233/600] => acc: 0.78667\n",
      "[test episode 234/600] => acc: 0.76000\n",
      "[test episode 235/600] => acc: 0.61333\n",
      "[test episode 236/600] => acc: 0.89333\n",
      "[test episode 237/600] => acc: 0.68000\n",
      "[test episode 238/600] => acc: 0.61333\n",
      "[test episode 239/600] => acc: 0.76000\n",
      "[test episode 240/600] => acc: 0.70667\n",
      "[test episode 241/600] => acc: 0.76000\n",
      "[test episode 242/600] => acc: 0.80000\n",
      "[test episode 243/600] => acc: 0.76000\n",
      "[test episode 244/600] => acc: 0.73333\n",
      "[test episode 245/600] => acc: 0.69333\n",
      "[test episode 246/600] => acc: 0.81333\n",
      "[test episode 247/600] => acc: 0.64000\n",
      "[test episode 248/600] => acc: 0.62667\n",
      "[test episode 249/600] => acc: 0.62667\n",
      "[test episode 250/600] => acc: 0.61333\n",
      "[test episode 251/600] => acc: 0.76000\n",
      "[test episode 252/600] => acc: 0.56000\n",
      "[test episode 253/600] => acc: 0.54667\n",
      "[test episode 254/600] => acc: 0.85333\n",
      "[test episode 255/600] => acc: 0.65333\n",
      "[test episode 256/600] => acc: 0.65333\n",
      "[test episode 257/600] => acc: 0.65333\n",
      "[test episode 258/600] => acc: 0.73333\n",
      "[test episode 259/600] => acc: 0.72000\n",
      "[test episode 260/600] => acc: 0.60000\n",
      "[test episode 261/600] => acc: 0.77333\n",
      "[test episode 262/600] => acc: 0.82667\n",
      "[test episode 263/600] => acc: 0.81333\n",
      "[test episode 264/600] => acc: 0.85333\n",
      "[test episode 265/600] => acc: 0.61333\n",
      "[test episode 266/600] => acc: 0.82667\n",
      "[test episode 267/600] => acc: 0.76000\n",
      "[test episode 268/600] => acc: 0.80000\n",
      "[test episode 269/600] => acc: 0.77333\n",
      "[test episode 270/600] => acc: 0.76000\n",
      "[test episode 271/600] => acc: 0.78667\n",
      "[test episode 272/600] => acc: 0.70667\n",
      "[test episode 273/600] => acc: 0.73333\n",
      "[test episode 274/600] => acc: 0.56000\n",
      "[test episode 275/600] => acc: 0.78667\n",
      "[test episode 276/600] => acc: 0.65333\n",
      "[test episode 277/600] => acc: 0.80000\n",
      "[test episode 278/600] => acc: 0.57333\n",
      "[test episode 279/600] => acc: 0.66667\n",
      "[test episode 280/600] => acc: 0.80000\n",
      "[test episode 281/600] => acc: 0.58667\n",
      "[test episode 282/600] => acc: 0.82667\n",
      "[test episode 283/600] => acc: 0.66667\n",
      "[test episode 284/600] => acc: 0.76000\n",
      "[test episode 285/600] => acc: 0.80000\n",
      "[test episode 286/600] => acc: 0.80000\n",
      "[test episode 287/600] => acc: 0.61333\n",
      "[test episode 288/600] => acc: 0.65333\n",
      "[test episode 289/600] => acc: 0.62667\n",
      "[test episode 290/600] => acc: 0.48000\n",
      "[test episode 291/600] => acc: 0.84000\n",
      "[test episode 292/600] => acc: 0.62667\n",
      "[test episode 293/600] => acc: 0.78667\n",
      "[test episode 294/600] => acc: 0.80000\n",
      "[test episode 295/600] => acc: 0.76000\n",
      "[test episode 296/600] => acc: 0.76000\n",
      "[test episode 297/600] => acc: 0.84000\n",
      "[test episode 298/600] => acc: 0.72000\n",
      "[test episode 299/600] => acc: 0.74667\n",
      "[test episode 300/600] => acc: 0.74667\n",
      "[test episode 301/600] => acc: 0.82667\n",
      "[test episode 302/600] => acc: 0.60000\n",
      "[test episode 303/600] => acc: 0.65333\n",
      "[test episode 304/600] => acc: 0.60000\n",
      "[test episode 305/600] => acc: 0.65333\n",
      "[test episode 306/600] => acc: 0.70667\n",
      "[test episode 307/600] => acc: 0.86667\n",
      "[test episode 308/600] => acc: 0.64000\n",
      "[test episode 309/600] => acc: 0.64000\n",
      "[test episode 310/600] => acc: 0.73333\n",
      "[test episode 311/600] => acc: 0.82667\n",
      "[test episode 312/600] => acc: 0.90667\n",
      "[test episode 313/600] => acc: 0.62667\n",
      "[test episode 314/600] => acc: 0.60000\n",
      "[test episode 315/600] => acc: 0.72000\n",
      "[test episode 316/600] => acc: 0.72000\n",
      "[test episode 317/600] => acc: 0.65333\n",
      "[test episode 318/600] => acc: 0.62667\n",
      "[test episode 319/600] => acc: 0.85333\n",
      "[test episode 320/600] => acc: 0.62667\n",
      "[test episode 321/600] => acc: 0.81333\n",
      "[test episode 322/600] => acc: 0.80000\n",
      "[test episode 323/600] => acc: 0.72000\n",
      "[test episode 324/600] => acc: 0.73333\n",
      "[test episode 325/600] => acc: 0.69333\n",
      "[test episode 326/600] => acc: 0.80000\n",
      "[test episode 327/600] => acc: 0.85333\n",
      "[test episode 328/600] => acc: 0.73333\n",
      "[test episode 329/600] => acc: 0.80000\n",
      "[test episode 330/600] => acc: 0.77333\n",
      "[test episode 331/600] => acc: 0.84000\n",
      "[test episode 332/600] => acc: 0.86667\n",
      "[test episode 333/600] => acc: 0.78667\n",
      "[test episode 334/600] => acc: 0.85333\n",
      "[test episode 335/600] => acc: 0.90667\n",
      "[test episode 336/600] => acc: 0.78667\n",
      "[test episode 337/600] => acc: 0.89333\n",
      "[test episode 338/600] => acc: 0.78667\n",
      "[test episode 339/600] => acc: 0.82667\n",
      "[test episode 340/600] => acc: 0.64000\n",
      "[test episode 341/600] => acc: 0.84000\n",
      "[test episode 342/600] => acc: 0.61333\n",
      "[test episode 343/600] => acc: 0.80000\n",
      "[test episode 344/600] => acc: 0.76000\n",
      "[test episode 345/600] => acc: 0.74667\n",
      "[test episode 346/600] => acc: 0.66667\n",
      "[test episode 347/600] => acc: 0.74667\n",
      "[test episode 348/600] => acc: 0.80000\n",
      "[test episode 349/600] => acc: 0.81333\n",
      "[test episode 350/600] => acc: 0.57333\n",
      "[test episode 351/600] => acc: 0.61333\n",
      "[test episode 352/600] => acc: 0.74667\n",
      "[test episode 353/600] => acc: 0.58667\n",
      "[test episode 354/600] => acc: 0.70667\n",
      "[test episode 355/600] => acc: 0.69333\n",
      "[test episode 356/600] => acc: 0.72000\n",
      "[test episode 357/600] => acc: 0.70667\n",
      "[test episode 358/600] => acc: 0.76000\n",
      "[test episode 359/600] => acc: 0.69333\n",
      "[test episode 360/600] => acc: 0.77333\n",
      "[test episode 361/600] => acc: 0.66667\n",
      "[test episode 362/600] => acc: 0.81333\n",
      "[test episode 363/600] => acc: 0.73333\n",
      "[test episode 364/600] => acc: 0.69333\n",
      "[test episode 365/600] => acc: 0.64000\n",
      "[test episode 366/600] => acc: 0.76000\n",
      "[test episode 367/600] => acc: 0.54667\n",
      "[test episode 368/600] => acc: 0.73333\n",
      "[test episode 369/600] => acc: 0.80000\n",
      "[test episode 370/600] => acc: 0.76000\n",
      "[test episode 371/600] => acc: 0.76000\n",
      "[test episode 372/600] => acc: 0.66667\n",
      "[test episode 373/600] => acc: 0.89333\n",
      "[test episode 374/600] => acc: 0.93333\n",
      "[test episode 375/600] => acc: 0.64000\n",
      "[test episode 376/600] => acc: 0.73333\n",
      "[test episode 377/600] => acc: 0.76000\n",
      "[test episode 378/600] => acc: 0.72000\n",
      "[test episode 379/600] => acc: 0.50667\n",
      "[test episode 380/600] => acc: 0.60000\n",
      "[test episode 381/600] => acc: 0.84000\n",
      "[test episode 382/600] => acc: 0.81333\n",
      "[test episode 383/600] => acc: 0.89333\n",
      "[test episode 384/600] => acc: 0.81333\n",
      "[test episode 385/600] => acc: 0.57333\n",
      "[test episode 386/600] => acc: 0.84000\n",
      "[test episode 387/600] => acc: 0.70667\n",
      "[test episode 388/600] => acc: 0.56000\n",
      "[test episode 389/600] => acc: 0.61333\n",
      "[test episode 390/600] => acc: 0.76000\n",
      "[test episode 391/600] => acc: 0.88000\n",
      "[test episode 392/600] => acc: 0.70667\n",
      "[test episode 393/600] => acc: 0.80000\n",
      "[test episode 394/600] => acc: 0.77333\n",
      "[test episode 395/600] => acc: 0.72000\n",
      "[test episode 396/600] => acc: 0.78667\n",
      "[test episode 397/600] => acc: 0.62667\n",
      "[test episode 398/600] => acc: 0.77333\n",
      "[test episode 399/600] => acc: 0.72000\n",
      "[test episode 400/600] => acc: 0.62667\n",
      "[test episode 401/600] => acc: 0.76000\n",
      "[test episode 402/600] => acc: 0.62667\n",
      "[test episode 403/600] => acc: 0.84000\n",
      "[test episode 404/600] => acc: 0.78667\n",
      "[test episode 405/600] => acc: 0.62667\n",
      "[test episode 406/600] => acc: 0.77333\n",
      "[test episode 407/600] => acc: 0.77333\n",
      "[test episode 408/600] => acc: 0.69333\n",
      "[test episode 409/600] => acc: 0.69333\n",
      "[test episode 410/600] => acc: 0.64000\n",
      "[test episode 411/600] => acc: 0.72000\n",
      "[test episode 412/600] => acc: 0.80000\n",
      "[test episode 413/600] => acc: 0.53333\n",
      "[test episode 414/600] => acc: 0.76000\n",
      "[test episode 415/600] => acc: 0.69333\n",
      "[test episode 416/600] => acc: 0.77333\n",
      "[test episode 417/600] => acc: 0.77333\n",
      "[test episode 418/600] => acc: 0.65333\n",
      "[test episode 419/600] => acc: 0.58667\n",
      "[test episode 420/600] => acc: 0.68000\n",
      "[test episode 421/600] => acc: 0.81333\n",
      "[test episode 422/600] => acc: 0.69333\n",
      "[test episode 423/600] => acc: 0.73333\n",
      "[test episode 424/600] => acc: 0.62667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test episode 425/600] => acc: 0.81333\n",
      "[test episode 426/600] => acc: 0.60000\n",
      "[test episode 427/600] => acc: 0.61333\n",
      "[test episode 428/600] => acc: 0.74667\n",
      "[test episode 429/600] => acc: 0.72000\n",
      "[test episode 430/600] => acc: 0.78667\n",
      "[test episode 431/600] => acc: 0.73333\n",
      "[test episode 432/600] => acc: 0.65333\n",
      "[test episode 433/600] => acc: 0.65333\n",
      "[test episode 434/600] => acc: 0.88000\n",
      "[test episode 435/600] => acc: 0.88000\n",
      "[test episode 436/600] => acc: 0.81333\n",
      "[test episode 437/600] => acc: 0.68000\n",
      "[test episode 438/600] => acc: 0.64000\n",
      "[test episode 439/600] => acc: 0.84000\n",
      "[test episode 440/600] => acc: 0.84000\n",
      "[test episode 441/600] => acc: 0.62667\n",
      "[test episode 442/600] => acc: 0.80000\n",
      "[test episode 443/600] => acc: 0.92000\n",
      "[test episode 444/600] => acc: 0.74667\n",
      "[test episode 445/600] => acc: 0.70667\n",
      "[test episode 446/600] => acc: 0.81333\n",
      "[test episode 447/600] => acc: 0.74667\n",
      "[test episode 448/600] => acc: 0.56000\n",
      "[test episode 449/600] => acc: 0.80000\n",
      "[test episode 450/600] => acc: 0.80000\n",
      "[test episode 451/600] => acc: 0.50667\n",
      "[test episode 452/600] => acc: 0.68000\n",
      "[test episode 453/600] => acc: 0.80000\n",
      "[test episode 454/600] => acc: 0.78667\n",
      "[test episode 455/600] => acc: 0.80000\n",
      "[test episode 456/600] => acc: 0.88000\n",
      "[test episode 457/600] => acc: 0.80000\n",
      "[test episode 458/600] => acc: 0.72000\n",
      "[test episode 459/600] => acc: 0.73333\n",
      "[test episode 460/600] => acc: 0.72000\n",
      "[test episode 461/600] => acc: 0.69333\n",
      "[test episode 462/600] => acc: 0.69333\n",
      "[test episode 463/600] => acc: 0.64000\n",
      "[test episode 464/600] => acc: 0.58667\n",
      "[test episode 465/600] => acc: 0.62667\n",
      "[test episode 466/600] => acc: 0.70667\n",
      "[test episode 467/600] => acc: 0.61333\n",
      "[test episode 468/600] => acc: 0.86667\n",
      "[test episode 469/600] => acc: 0.66667\n",
      "[test episode 470/600] => acc: 0.68000\n",
      "[test episode 471/600] => acc: 0.61333\n",
      "[test episode 472/600] => acc: 0.74667\n",
      "[test episode 473/600] => acc: 0.78667\n",
      "[test episode 474/600] => acc: 0.76000\n",
      "[test episode 475/600] => acc: 0.56000\n",
      "[test episode 476/600] => acc: 0.66667\n",
      "[test episode 477/600] => acc: 0.54667\n",
      "[test episode 478/600] => acc: 0.69333\n",
      "[test episode 479/600] => acc: 0.82667\n",
      "[test episode 480/600] => acc: 0.84000\n",
      "[test episode 481/600] => acc: 0.82667\n",
      "[test episode 482/600] => acc: 0.69333\n",
      "[test episode 483/600] => acc: 0.54667\n",
      "[test episode 484/600] => acc: 0.62667\n",
      "[test episode 485/600] => acc: 0.76000\n",
      "[test episode 486/600] => acc: 0.70667\n",
      "[test episode 487/600] => acc: 0.76000\n",
      "[test episode 488/600] => acc: 0.69333\n",
      "[test episode 489/600] => acc: 0.82667\n",
      "[test episode 490/600] => acc: 0.72000\n",
      "[test episode 491/600] => acc: 0.69333\n",
      "[test episode 492/600] => acc: 0.76000\n",
      "[test episode 493/600] => acc: 0.77333\n",
      "[test episode 494/600] => acc: 0.66667\n",
      "[test episode 495/600] => acc: 0.73333\n",
      "[test episode 496/600] => acc: 0.69333\n",
      "[test episode 497/600] => acc: 0.89333\n",
      "[test episode 498/600] => acc: 0.69333\n",
      "[test episode 499/600] => acc: 0.74667\n",
      "[test episode 500/600] => acc: 0.80000\n",
      "[test episode 501/600] => acc: 0.86667\n",
      "[test episode 502/600] => acc: 0.78667\n",
      "[test episode 503/600] => acc: 0.73333\n",
      "[test episode 504/600] => acc: 0.89333\n",
      "[test episode 505/600] => acc: 0.77333\n",
      "[test episode 506/600] => acc: 0.66667\n",
      "[test episode 507/600] => acc: 0.85333\n",
      "[test episode 508/600] => acc: 0.68000\n",
      "[test episode 509/600] => acc: 0.74667\n",
      "[test episode 510/600] => acc: 0.58667\n",
      "[test episode 511/600] => acc: 0.72000\n",
      "[test episode 512/600] => acc: 0.72000\n",
      "[test episode 513/600] => acc: 0.77333\n",
      "[test episode 514/600] => acc: 0.73333\n",
      "[test episode 515/600] => acc: 0.69333\n",
      "[test episode 516/600] => acc: 0.69333\n",
      "[test episode 517/600] => acc: 0.57333\n",
      "[test episode 518/600] => acc: 0.68000\n",
      "[test episode 519/600] => acc: 0.80000\n",
      "[test episode 520/600] => acc: 0.72000\n",
      "[test episode 521/600] => acc: 0.64000\n",
      "[test episode 522/600] => acc: 0.70667\n",
      "[test episode 523/600] => acc: 0.78667\n",
      "[test episode 524/600] => acc: 0.78667\n",
      "[test episode 525/600] => acc: 0.73333\n",
      "[test episode 526/600] => acc: 0.84000\n",
      "[test episode 527/600] => acc: 0.80000\n",
      "[test episode 528/600] => acc: 0.61333\n",
      "[test episode 529/600] => acc: 0.72000\n",
      "[test episode 530/600] => acc: 0.65333\n",
      "[test episode 531/600] => acc: 0.80000\n",
      "[test episode 532/600] => acc: 0.69333\n",
      "[test episode 533/600] => acc: 0.69333\n",
      "[test episode 534/600] => acc: 0.64000\n",
      "[test episode 535/600] => acc: 0.53333\n",
      "[test episode 536/600] => acc: 0.65333\n",
      "[test episode 537/600] => acc: 0.45333\n",
      "[test episode 538/600] => acc: 0.74667\n",
      "[test episode 539/600] => acc: 0.81333\n",
      "[test episode 540/600] => acc: 0.84000\n",
      "[test episode 541/600] => acc: 0.72000\n",
      "[test episode 542/600] => acc: 0.74667\n",
      "[test episode 543/600] => acc: 0.69333\n",
      "[test episode 544/600] => acc: 0.72000\n",
      "[test episode 545/600] => acc: 0.76000\n",
      "[test episode 546/600] => acc: 0.76000\n",
      "[test episode 547/600] => acc: 0.81333\n",
      "[test episode 548/600] => acc: 0.90667\n",
      "[test episode 549/600] => acc: 0.73333\n",
      "[test episode 550/600] => acc: 0.78667\n",
      "[test episode 551/600] => acc: 0.66667\n",
      "[test episode 552/600] => acc: 0.65333\n",
      "[test episode 553/600] => acc: 0.74667\n",
      "[test episode 554/600] => acc: 0.81333\n",
      "[test episode 555/600] => acc: 0.77333\n",
      "[test episode 556/600] => acc: 0.82667\n",
      "[test episode 557/600] => acc: 0.70667\n",
      "[test episode 558/600] => acc: 0.61333\n",
      "[test episode 559/600] => acc: 0.90667\n",
      "[test episode 560/600] => acc: 0.76000\n",
      "[test episode 561/600] => acc: 0.57333\n",
      "[test episode 562/600] => acc: 0.80000\n",
      "[test episode 563/600] => acc: 0.80000\n",
      "[test episode 564/600] => acc: 0.80000\n",
      "[test episode 565/600] => acc: 0.68000\n",
      "[test episode 566/600] => acc: 0.53333\n",
      "[test episode 567/600] => acc: 0.65333\n",
      "[test episode 568/600] => acc: 0.74667\n",
      "[test episode 569/600] => acc: 0.76000\n",
      "[test episode 570/600] => acc: 0.88000\n",
      "[test episode 571/600] => acc: 0.48000\n",
      "[test episode 572/600] => acc: 0.60000\n",
      "[test episode 573/600] => acc: 0.65333\n",
      "[test episode 574/600] => acc: 0.69333\n",
      "[test episode 575/600] => acc: 0.62667\n",
      "[test episode 576/600] => acc: 0.70667\n",
      "[test episode 577/600] => acc: 0.82667\n",
      "[test episode 578/600] => acc: 0.53333\n",
      "[test episode 579/600] => acc: 0.70667\n",
      "[test episode 580/600] => acc: 0.77333\n",
      "[test episode 581/600] => acc: 0.88000\n",
      "[test episode 582/600] => acc: 0.74667\n",
      "[test episode 583/600] => acc: 0.40000\n",
      "[test episode 584/600] => acc: 0.58667\n",
      "[test episode 585/600] => acc: 0.66667\n",
      "[test episode 586/600] => acc: 0.76000\n",
      "[test episode 587/600] => acc: 0.61333\n",
      "[test episode 588/600] => acc: 0.61333\n",
      "[test episode 589/600] => acc: 0.61333\n",
      "[test episode 590/600] => acc: 0.73333\n",
      "[test episode 591/600] => acc: 0.65333\n",
      "[test episode 592/600] => acc: 0.82667\n",
      "[test episode 593/600] => acc: 0.74667\n",
      "[test episode 594/600] => acc: 0.85333\n",
      "[test episode 595/600] => acc: 0.77333\n",
      "[test episode 596/600] => acc: 0.61333\n",
      "[test episode 597/600] => acc: 0.56000\n",
      "[test episode 598/600] => acc: 0.72000\n",
      "[test episode 599/600] => acc: 0.72000\n",
      "[test episode 600/600] => acc: 0.82667\n",
      "Average Test Accuracy: 0.72540\n"
     ]
    }
   ],
   "source": [
    "print('Testing...')\n",
    "avg_acc = 0.\n",
    "for epi in range(n_test_episodes):\n",
    "    epi_classes = np.random.permutation(n_classes)[:n_test_way]\n",
    "    support = np.zeros([n_test_way, n_test_shot, im_height, im_width, channels], dtype=np.float32)\n",
    "    query = np.zeros([n_test_way, n_test_query, im_height, im_width, channels], dtype=np.float32)\n",
    "    for i, epi_cls in enumerate(epi_classes):\n",
    "        selected = np.random.permutation(n_examples)[:n_test_shot + n_test_query]\n",
    "        support[i] = test_dataset[epi_cls, selected[:n_test_shot]]\n",
    "        query[i] = test_dataset[epi_cls, selected[n_test_shot:]]\n",
    "        \n",
    "    correct = 0\n",
    "    incorrect=0\n",
    "    total_num = 0\n",
    "    for q_label, q_set in enumerate(query):\n",
    "        for q in q_set:\n",
    "            total_num+=1\n",
    "            #print('query input!')\n",
    "            scores = []\n",
    "            for s_label, s_set in enumerate(support):\n",
    "                q2s_set_score = 0\n",
    "                for s in s_set:\n",
    "                    q2s_set_score+=matching_scoring(q, s)\n",
    "                scores.append(q2s_set_score)\n",
    "            if np.argmax(scores) == q_label:\n",
    "                correct+=1\n",
    "                #print('correct!')\n",
    "            else:\n",
    "                incorrect+=1\n",
    "    ac = correct/total_num\n",
    "    avg_acc+=ac\n",
    "    print('[test episode {}/{}] => acc: {:.5f}'.format(epi+1, n_test_episodes, ac))\n",
    "avg_acc /= n_test_episodes\n",
    "print('Average Test Accuracy: {:.5f}'.format(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "x+= 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, category in enumerate(support):\n",
    "    print(idx, category.shape)\n",
    "    for q in category:\n",
    "        print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing...')\n",
    "avg_acc = 0.\n",
    "for epi in range(n_test_episodes):\n",
    "    epi_classes = np.random.permutation(n_test_classes)[:n_test_way]\n",
    "    support = np.zeros([n_test_way, n_test_shot, im_height, im_width, channels], dtype=np.float32)\n",
    "    query = np.zeros([n_test_way, n_test_query, im_height, im_width, channels], dtype=np.float32)\n",
    "    for i, epi_cls in enumerate(epi_classes):\n",
    "        selected = np.random.permutation(n_examples)[:n_test_shot + n_test_query]\n",
    "        support[i] = test_dataset[epi_cls, selected[:n_test_shot]]\n",
    "        query[i] = test_dataset[epi_cls, selected[n_test_shot:]]\n",
    "\n",
    "        \n",
    "        \n",
    "    labels = np.tile(np.arange(n_test_way)[:, np.newaxis], (1, n_test_query)).astype(np.uint8)\n",
    "    ls, ac = sess.run([ce_loss, acc], feed_dict={x: support, q: query, y:labels})\n",
    "    avg_acc += ac\n",
    "    if (epi+1) % 50 == 0:\n",
    "        print('[test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_test_episodes, ls, ac))\n",
    "avg_acc /= n_test_episodes\n",
    "print('Average Test Accuracy: {:.5f}'.format(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(n_epochs):\n",
    "    for epi in range(n_episodes):\n",
    "        epi_classes = np.random.permutation(n_classes)[:n_way]\n",
    "        support = np.zeros([n_way, n_shot, im_height, im_width, channels], dtype=np.float32)\n",
    "        query = np.zeros([n_way, n_query, im_height, im_width, channels], dtype=np.float32)\n",
    "        for i, epi_cls in enumerate(epi_classes):\n",
    "            selected = np.random.permutation(n_examples)[:n_shot + n_query]\n",
    "            support[i] = test_dataset[epi_cls, selected[:n_shot]]\n",
    "            query[i] = test_dataset[epi_cls, selected[n_shot:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers = ['datasets/1.jpg', 'datasets/2.jpg']\n",
    "dogs = ['datasets/3.JPEG', 'datasets/4.JPEG']\n",
    "armours = ['datasets/5.JPEG', 'datasets/6.JPEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_groups = {'tps_grid_size': 3, \n",
    "              'tps_reg_factor': 0.2, \n",
    "              'normalize_inlier_count': True, \n",
    "              'dilation_filter': 0, 'use_conv_filter': False}\n",
    "inliersAffine = WeakInlierCount(geometric_model='affine',**arg_groups)\n",
    "#inliersTps = WeakInlierCount(geometric_model='tps',**arg_groups['weak_loss'])\n",
    "inliersComposed = TwoStageWeakInlierCount(use_cuda=use_cuda,**arg_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeCNN = GeometricTnf(out_h=240, out_w=240, use_cuda = False) \n",
    "normalizeTnf = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # convert to torch Variable\n",
    "    image = np.expand_dims(image.transpose((2,0,1)),0)\n",
    "    image = torch.Tensor(image.astype(np.float32)/255.0)\n",
    "    image_var = Variable(image,requires_grad=False)\n",
    "\n",
    "    # Resize image using bilinear sampling with identity affine tnf\n",
    "    image_var = resizeCNN(image_var)\n",
    "    \n",
    "    # Normalize image\n",
    "    image_var = normalize_image(image_var)\n",
    "    \n",
    "    return image_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(flowers, flowers):\n",
    "    source_image = io.imread(a)\n",
    "    target_image = io.imread(b)\n",
    "    source_image_var = preprocess_image(source_image)\n",
    "    target_image_var = preprocess_image(target_image)\n",
    "\n",
    "    if use_cuda:\n",
    "        source_image_var = source_image_var.cuda()\n",
    "        target_image_var = target_image_var.cuda()\n",
    "\n",
    "    batch = {'source_image': source_image_var, 'target_image':target_image_var}   \n",
    "    theta_aff,theta_aff_tps,corr_aff,corr_aff_tps=model(batch)\n",
    "    inliers_comp = inliersComposed(matches=corr_aff,theta_aff=theta_aff,theta_aff_tps=theta_aff_tps)\n",
    "    inliers_aff = inliersAffine(matches=corr_aff,theta=theta_aff)\n",
    "    \n",
    "    \n",
    "    print(\"inliers_aff : {} \\n inliers_comp : {} \\n total {}: \".format(inliers_aff.data.cpu().numpy()[0], \n",
    "                                                                     inliers_comp.data.cpu().numpy()[0], \n",
    "                                                                     (inliers_aff+inliers_comp).data.cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"inliers_aff : {} \\n inliers_comp : {} \\n total {}: \".format(inliers_aff.data.cpu().numpy()[0], \n",
    "                                                                     inliers_comp.data.cpu().numpy()[0], \n",
    "                                                                     inliers_aff.data.cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image = io.imread(source_image_path)\n",
    "target_image = io.imread(target_image_path)\n",
    "\n",
    "source_image_var = preprocess_image(source_image)\n",
    "target_image_var = preprocess_image(target_image)\n",
    "\n",
    "if use_cuda:\n",
    "    source_image_var = source_image_var.cuda()\n",
    "    target_image_var = target_image_var.cuda()\n",
    "\n",
    "batch = {'source_image': source_image_var, 'target_image':target_image_var}\n",
    "\n",
    "resizeTgt = GeometricTnf(out_h=target_image.shape[0], out_w=target_image.shape[1], use_cuda = use_cuda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_images = [io.imread(x) for x in flowers]\n",
    "target_images = [io.imread(x) for x in dogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_images = [preprocess_image(io.imread(x)).cuda() for x in flowers]\n",
    "target_images = [preprocess_image(io.imread(x)).cuda() for x in dogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack(source_images, axis=0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {'source_image': source_images, 'target_image':target_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Evaluate model\n",
    "#theta_aff,theta_aff_tps=model(batch)\n",
    "theta_aff,theta_aff_tps,corr_aff,corr_aff_tps=model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_groups = {'tps_grid_size': 3, 'tps_reg_factor': 0.2, 'normalize_inlier_count': True, 'dilation_filter': 0, 'use_conv_filter': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliersAffine = WeakInlierCount(geometric_model='affine',**arg_groups)\n",
    "#inliersTps = WeakInlierCount(geometric_model='tps',**arg_groups['weak_loss'])\n",
    "inliersComposed = TwoStageWeakInlierCount(use_cuda=use_cuda,**arg_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers_comp = inliersComposed(matches=corr_aff,\n",
    "                                                 theta_aff=theta_aff,\n",
    "                                                 theta_aff_tps=theta_aff_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers_aff = inliersAffine(matches=corr_aff,\n",
    "                                theta=theta_aff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute warped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affTpsTnf(source_image, theta_aff, theta_aff_tps, use_cuda=use_cuda):\n",
    "    tpstnf = GeometricTnf(geometric_model = 'tps',use_cuda=use_cuda)\n",
    "    sampling_grid = tpstnf(image_batch=source_image,\n",
    "                           theta_batch=theta_aff_tps,\n",
    "                           return_sampling_grid=True)[1]\n",
    "    X = sampling_grid[:,:,:,0].unsqueeze(3)\n",
    "    Y = sampling_grid[:,:,:,1].unsqueeze(3)\n",
    "    Xp = X*theta_aff[:,0].unsqueeze(1).unsqueeze(2)+Y*theta_aff[:,1].unsqueeze(1).unsqueeze(2)+theta_aff[:,2].unsqueeze(1).unsqueeze(2)\n",
    "    Yp = X*theta_aff[:,3].unsqueeze(1).unsqueeze(2)+Y*theta_aff[:,4].unsqueeze(1).unsqueeze(2)+theta_aff[:,5].unsqueeze(1).unsqueeze(2)\n",
    "    sg = torch.cat((Xp,Yp),3)\n",
    "    warped_image_batch = F.grid_sample(source_image, sg)\n",
    "\n",
    "    return warped_image_batch\n",
    "\n",
    "warped_image_aff = affTnf(batch['source_image'],theta_aff.view(-1,2,3))\n",
    "warped_image_aff_tps = affTpsTnf(batch['source_image'],theta_aff,theta_aff_tps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-normalize images and convert to numpy\n",
    "warped_image_aff_np = normalize_image(resizeTgt(warped_image_aff),forward=False).data.squeeze(0).transpose(0,1).transpose(1,2).cpu().numpy()\n",
    "warped_image_aff_tps_np = normalize_image(resizeTgt(warped_image_aff_tps),forward=False).data.squeeze(0).transpose(0,1).transpose(1,2).cpu().numpy()\n",
    "\n",
    "N_subplots = 4\n",
    "fig, axs = plt.subplots(1,N_subplots)\n",
    "axs[0].imshow(source_image)\n",
    "axs[0].set_title('src')\n",
    "axs[1].imshow(target_image)\n",
    "axs[1].set_title('tgt')\n",
    "axs[2].imshow(warped_image_aff_np)\n",
    "axs[2].set_title('aff')\n",
    "axs[3].imshow(warped_image_aff_tps_np)\n",
    "axs[3].set_title('aff+tps')\n",
    "\n",
    "for i in range(N_subplots):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "fig.set_dpi(150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inliers_aff : {} \\n inliers_comp : {} \\n total {}: \".format(inliers_aff.data, \n",
    "                                                                 inliers_comp.data, \n",
    "                                                                 inliers_aff.data+inliers_comp.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
